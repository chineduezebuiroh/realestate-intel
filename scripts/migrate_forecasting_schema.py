# scripts/migrate_forecasting_schema.py
import os
import duckdb
from dotenv import load_dotenv

load_dotenv()
DUCKDB_PATH = os.getenv("DUCKDB_PATH", "./data/market.duckdb")

FORECAST_DDL = """
-- 1) Metadata for each forecast run (vintage)
CREATE TABLE IF NOT EXISTS forecast_runs (
    run_id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    created_at TIMESTAMP NOT NULL DEFAULT now(),

    -- What we’re forecasting
    model_name TEXT NOT NULL,
    model_version TEXT NOT NULL,
    target_metric_id TEXT NOT NULL,
    target_geo_id TEXT NOT NULL,
    target_property_type_id INTEGER,       -- NULL = geo-level metric w/o property type

    -- Frequency & horizon
    freq TEXT NOT NULL,
    train_start DATE NOT NULL,
    train_end DATE NOT NULL,
    horizon_max_months INTEGER NOT NULL,

    -- Model config / metadata
    algo_params_json JSON,
    notes TEXT,
    is_active BOOLEAN NOT NULL DEFAULT TRUE
);

-- 2) Forecasted values per (run_id, target_date)
CREATE TABLE IF NOT EXISTS forecast_predictions (
    run_id BIGINT NOT NULL,
    target_date DATE NOT NULL,
    horizon_steps INTEGER NOT NULL,
    horizon_months INTEGER NOT NULL,
    y_hat DOUBLE NOT NULL,
    y_hat_lo DOUBLE,
    y_hat_hi DOUBLE,

    PRIMARY KEY (run_id, target_date),
    FOREIGN KEY (run_id) REFERENCES forecast_runs(run_id)
);

-- 3) Evaluation view — wide, per run_id, multi-horizon metrics
CREATE OR REPLACE VIEW v_forecast_eval AS
WITH joined AS (
    SELECT
        p.run_id,
        p.target_date,
        p.horizon_months,
        p.y_hat,
        f.value AS actual
    FROM forecast_predictions p
    JOIN forecast_runs r ON r.run_id = p.run_id
    JOIN fact_timeseries f
      ON f.metric_id = r.target_metric_id
     AND f.geo_id = r.target_geo_id
     AND (
         (f.property_type_id IS NULL AND r.target_property_type_id IS NULL)
         OR (f.property_type_id = r.target_property_type_id)
     )
     AND f.date = p.target_date
),
per_horizon AS (
    SELECT
        run_id,
        horizon_months,
        AVG(ABS((actual - y_hat) / NULLIF(actual, 0))) * 100.0 AS mape,
        AVG(ABS(actual - y_hat)) AS mae,
        SQRT(AVG(POWER(actual - y_hat, 2))) AS rmse
    FROM joined
    WHERE actual IS NOT NULL
    GROUP BY run_id, horizon_months
)
SELECT
    run_id,

    MAX(CASE WHEN horizon_months = 1  THEN mape END) AS mape_1m,
    MAX(CASE WHEN horizon_months = 3  THEN mape END) AS mape_3m,
    MAX(CASE WHEN horizon_months = 6  THEN mape END) AS mape_6m,
    MAX(CASE WHEN horizon_months = 12 THEN mape END) AS mape_12m,

    MAX(CASE WHEN horizon_months = 1  THEN mae END) AS mae_1m,
    MAX(CASE WHEN horizon_months = 3  THEN mae_3m END) AS mae_3m,
    MAX(CASE WHEN horizon_months = 6  THEN mae_6m END) AS mae_6m,
    MAX(CASE WHEN horizon_months = 12 THEN mae_12m END) AS mae_12m,

    MAX(CASE WHEN horizon_months = 1  THEN rmse END) AS rmse_1m,
    MAX(CASE WHEN horizon_months = 3  THEN rmse_3m END) AS rmse_3m,
    MAX(CASE WHEN horizon_months = 6  THEN rmse_6m END) AS rmse_6m,
    MAX(CASE WHEN horizon_months = 12 THEN rmse_12m END) AS rmse_12m
FROM per_horizon
GROUP BY run_id;
"""

def migrate():
    con = duckdb.connect(DUCKDB_PATH)
    con.execute(FORECAST_DDL)
    con.close()
    print(f"[migrate] Forecast schema ensured at {DUCKDB_PATH}")

if __name__ == "__main__":
    migrate()
